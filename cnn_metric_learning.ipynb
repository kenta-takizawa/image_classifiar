{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+metric learning による異常検知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "boots = 9#ブーツは9\n",
    "sneaker = 7#スニーカーは7\n",
    "\n",
    "# dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "#学習データ\n",
    "x_train_sum, x_train_s, x_train_b, x_test_s, x_test_b, = [], [], [], [], []\n",
    "y_train_sum = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if y_train[i] == boots:\n",
    "        x_train_b.append(x_train[i])\n",
    "    elif y_train[i] == sneaker:\n",
    "        x_train_s.append(x_train[i])\n",
    "    else:\n",
    "        x_train_sum.append(x_train[i])\n",
    "        y_train_sum.append(y_train[i])\n",
    "\n",
    "x_train_sum = np.array(x_train_sum)\n",
    "x_train_b = np.array(x_train_b)\n",
    "x_train_s = np.array(x_train_s)\n",
    "        \n",
    "#trainデータからランダムに4000個抽出\n",
    "number = np.random.choice(np.arange(0,x_train_sum.shape[0]),4000,replace=False)\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for i in number:\n",
    "    x.append(x_train_sum[i])\n",
    "    y.append(y_train_sum[i])\n",
    "    \n",
    "x_train_sum = np.array(x)\n",
    "y_train_sum = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "(5000, 28, 28, 1)\n",
      "(5000, 10)\n",
      "(1000, 28, 28, 1)\n",
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#スニーカーデータからランダムに500個抽出\n",
    "number = np.random.choice(np.arange(0,x_train_s.shape[0]),500,replace=False)\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for i in number:\n",
    "    x.append(x_train_s[i])\n",
    "\n",
    "#データ結合\n",
    "x_train_sum = np.vstack((x_train_sum, np.array(x)))\n",
    "y_train_sum = np.hstack((y_train_sum, sneaker*np.ones(500)))\n",
    "\n",
    "#ブーツデータからランダムに10個抽出\n",
    "number = np.random.choice(np.arange(0,x_train_b.shape[0]),10,replace=False)\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for i in number:\n",
    "    x.append(x_train_b[i])\n",
    "    \n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             horizontal_flip=False)\n",
    "img = []\n",
    "\n",
    "for d in datagen.flow(np.array(x), batch_size=1):\n",
    "    # このあと画像を表示するためにndarrayをPIL形式に変換して保存する\n",
    "    img.append(d[0])\n",
    "    # datagen.flowは無限ループするため必要な枚数取得できたらループを抜ける\n",
    "    if len(img) == 500:\n",
    "        print(\"finish\")\n",
    "        break\n",
    "\n",
    "#データ結合\n",
    "x_train_sum = np.vstack((x_train_sum, np.array(img)))\n",
    "y_train_sum = np.hstack((y_train_sum, boots*np.ones(500)))\n",
    "y_train_sum = to_categorical(y_train_sum)\n",
    "\n",
    "#テストデータ\n",
    "for i in range(len(x_test)):\n",
    "    if y_test[i] == 7:#スニーカーは7\n",
    "        x_test_s.append(x_test[i])\n",
    "    \n",
    "    if y_test[i] == 9:#ブーツは9\n",
    "        x_test_b.append(x_test[i])\n",
    "    \n",
    "x_test_s = np.array(x_test_s)\n",
    "x_test_b = np.array(x_test_b)\n",
    "\n",
    "print(x_train_sum.shape)\n",
    "print(y_train_sum.shape)\n",
    "print(x_test_s.shape)\n",
    "print(x_test_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 96×96×3にリサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def resize(x):\n",
    "    x_out = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        img = cv2.cvtColor(x[i], cv2.COLOR_GRAY2RGB)\n",
    "        img = cv2.resize(img,dsize=(96,96))\n",
    "        x_out.append(img)\n",
    "                \n",
    "    return np.array(x_out)\n",
    "\n",
    "X_train_sum = resize(x_train_sum)\n",
    "X_test_s = resize(x_test_s)\n",
    "X_test_b = resize(x_test_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "input_shape = (96, 96, 3)\n",
    "classes = 10\n",
    "batchsize = 128\n",
    "alpha = 0.5\n",
    "\n",
    "def train_and_evaluate(number, anomaly=True):\n",
    "    # mobile net読み込み\n",
    "    print(\"Model build...\")\n",
    "    \n",
    "    mobile = MobileNetV2(include_top=True, input_shape=input_shape, alpha=alpha,\n",
    "                     weights='imagenet')\n",
    "    \n",
    "    # 最終層削除\n",
    "    mobile.layers.pop()\n",
    "    model = Model(inputs=mobile.input,outputs=mobile.layers[-1].output)\n",
    "            \n",
    "    # L2層と全結合層を付ける\n",
    "    c = keras.layers.Lambda(lambda xx: 5*(xx)/K.sqrt(K.sum(xx**2)))(model.output) #metric learning\n",
    "    c = Dense(classes, activation='softmax')(c)\n",
    "    model = Model(inputs=model.input,outputs=c)\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(amsgrad=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(number,\"training...\")\n",
    "\n",
    "    #cnnの学習\n",
    "    if anomaly == True:\n",
    "        train_NO = 5000\n",
    "    else:\n",
    "        train_NO = 4500\n",
    "\n",
    "    hist = model.fit(X_train_sum[:train_NO],\n",
    "                     y_train_sum[:train_NO],\n",
    "                     batch_size=128,\n",
    "                     epochs=50,\n",
    "                     verbose = False)\n",
    "    \n",
    "\n",
    "    # 最終層削除\n",
    "    model.layers.pop()\n",
    "    model = Model(inputs=model.input,outputs=model.layers[-1].output)\n",
    "\n",
    "    train = model.predict(X_train_sum[4000:4500], batch_size=1)#スニーカー\n",
    "    test_s = model.predict(X_test_s, batch_size=1)\n",
    "    test_b = model.predict(X_test_b, batch_size=1)\n",
    "\n",
    "    train = train.reshape((len(train),-1))\n",
    "    test_s = test_s.reshape((len(X_test_s),-1))\n",
    "    test_b = test_b.reshape((len(X_test_b),-1))\n",
    "\n",
    "    #0-1変換\n",
    "    ms = MinMaxScaler()\n",
    "    train = ms.fit_transform(train)\n",
    "    test_s = ms.transform(test_s)\n",
    "    test_b = ms.transform(test_b)\n",
    "\n",
    "    # LOF\n",
    "    clf = LocalOutlierFactor(n_neighbors=5)\n",
    "    y_pred = clf.fit(train)\n",
    "\n",
    "    # plot the level sets of the decision function\n",
    "    Z1 = -clf._decision_function(test_s)\n",
    "    Z2 = -clf._decision_function(test_b)\n",
    "\n",
    "    #ROC曲線の描画\n",
    "    y_true = np.zeros(len(test_s)+len(test_b))\n",
    "    y_true[len(test_s):] = 1#0:正常、1：異常\n",
    "\n",
    "    # FPR, TPR(, しきい値) を算出\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1, Z2)))\n",
    "\n",
    "    # AUC\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # ROC曲線をプロット\n",
    "    plt.plot(fpr, tpr, label='metric learning(AUC = %.2f)'%auc)\n",
    "    plt.legend()\n",
    "    plt.title(str(number)+'ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0309 21:27:13.926023 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model build...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0309 21:27:14.364250 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0309 21:27:14.395244 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0309 21:27:14.509208 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0309 21:27:14.512206 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0309 21:27:14.679641 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.5_96.h5\n",
      "8339456/8331712 [==============================] - 16s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0309 21:27:59.423449 22172 deprecation_wrapper.py:119] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0309 21:28:00.066251 22172 deprecation.py:323] From C:\\Users\\kenta takizawa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#　普通の異常検知\n",
    "for i in range(10):\n",
    "    train_and_evaluate(i+1, False)\n",
    "    \n",
    "#　弱異常検知\n",
    "for i in range(10):\n",
    "    train_and_evaluate(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
