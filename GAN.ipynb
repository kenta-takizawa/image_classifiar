{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "\n",
    "#生成者ネットワーク\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "\n",
    "x = layers.Dense(128*16*16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16,16,128))(x)\n",
    "\n",
    "x = layers.Conv2D(256,5,padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2,padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5,padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5,padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels,7,activation=\"tanh\",padding=\"same\")(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input,x)\n",
    "generator.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#判別者ネットワーク\n",
    "discriminator_input = layers.Input(shape=(height,width,channels))\n",
    "\n",
    "x = layers.Conv2D(128,3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128,4,strides=2)(x)\n",
    "x = layers.LeakyReLU()(x) \n",
    "x = layers.Conv2D(128,4,strides=2)(x)\n",
    "x = layers.LeakyReLU()(x) \n",
    "x = layers.Conv2D(128,4,strides=2)(x)\n",
    "x = layers.LeakyReLU()(x) \n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input,x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.008,clipvalue=1.0,decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,loss=\"binary_crossentropy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#敵対者ネットワーク　生成者と判別者をつなぎ合わせる\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "\n",
    "gan = keras.models.Model(gan_input,gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.004,clipvalue=1.0,decay=1e-8)\n",
    "\n",
    "gan.compile(optimizer=gan_optimizer,loss=\"binary_crossentropy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from keras.preprocessing import image\n",
    "\n",
    "(x_train,y_train),(_,_) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "#choose the images of frogs\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0],)+(height,width,channels)).astype(\"float32\") / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "\n",
    "save_dir = \"C:/Users/kenta takizawa/Desktop/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 0: 8.495903\n",
      "adversarial loss at step 0: 1.0000001e-07\n",
      "discriminator loss at step 100: 8.376001\n",
      "adversarial loss at step 100: 1.0000001e-07\n",
      "discriminator loss at step 200: 8.437133\n",
      "adversarial loss at step 200: 1.0000001e-07\n",
      "discriminator loss at step 300: 8.47573\n",
      "adversarial loss at step 300: 1.0000001e-07\n",
      "discriminator loss at step 400: 8.474376\n",
      "adversarial loss at step 400: 1.0000001e-07\n",
      "discriminator loss at step 500: 8.401718\n",
      "adversarial loss at step 500: 1.0000001e-07\n",
      "discriminator loss at step 600: 8.48398\n",
      "adversarial loss at step 600: 1.0000001e-07\n",
      "discriminator loss at step 700: 8.449086\n",
      "adversarial loss at step 700: 1.0000001e-07\n",
      "discriminator loss at step 800: 8.490149\n",
      "adversarial loss at step 800: 1.0000001e-07\n",
      "discriminator loss at step 900: 8.427663\n",
      "adversarial loss at step 900: 1.0000001e-07\n",
      "discriminator loss at step 1000: 8.438995\n",
      "adversarial loss at step 1000: 1.0000001e-07\n",
      "discriminator loss at step 1100: 8.479214\n",
      "adversarial loss at step 1100: 1.0000001e-07\n",
      "discriminator loss at step 1200: 8.454829\n",
      "adversarial loss at step 1200: 1.0000001e-07\n",
      "discriminator loss at step 1300: 8.425915\n",
      "adversarial loss at step 1300: 1.0000001e-07\n",
      "discriminator loss at step 1400: 8.401805\n",
      "adversarial loss at step 1400: 1.0000001e-07\n",
      "discriminator loss at step 1500: 8.478955\n",
      "adversarial loss at step 1500: 1.0000001e-07\n",
      "discriminator loss at step 1600: 8.508651\n",
      "adversarial loss at step 1600: 1.0000001e-07\n",
      "discriminator loss at step 1700: 8.406458\n",
      "adversarial loss at step 1700: 1.0000001e-07\n",
      "discriminator loss at step 1800: 8.426206\n",
      "adversarial loss at step 1800: 1.0000001e-07\n",
      "discriminator loss at step 1900: 8.474674\n",
      "adversarial loss at step 1900: 1.0000001e-07\n",
      "discriminator loss at step 2000: 8.404744\n",
      "adversarial loss at step 2000: 1.0000001e-07\n",
      "discriminator loss at step 2100: 8.414528\n",
      "adversarial loss at step 2100: 1.0000001e-07\n",
      "discriminator loss at step 2200: 8.370343\n",
      "adversarial loss at step 2200: 1.0000001e-07\n",
      "discriminator loss at step 2300: 8.457983\n",
      "adversarial loss at step 2300: 1.0000001e-07\n",
      "discriminator loss at step 2400: 8.4565525\n",
      "adversarial loss at step 2400: 1.0000001e-07\n",
      "discriminator loss at step 2500: 8.464467\n",
      "adversarial loss at step 2500: 1.0000001e-07\n",
      "discriminator loss at step 2600: 8.522003\n",
      "adversarial loss at step 2600: 1.0000001e-07\n",
      "discriminator loss at step 2700: 8.452344\n",
      "adversarial loss at step 2700: 1.0000001e-07\n",
      "discriminator loss at step 2800: 8.469623\n",
      "adversarial loss at step 2800: 1.0000001e-07\n",
      "discriminator loss at step 2900: 8.440801\n",
      "adversarial loss at step 2900: 1.0000001e-07\n",
      "discriminator loss at step 3000: 8.458765\n",
      "adversarial loss at step 3000: 1.0000001e-07\n",
      "discriminator loss at step 3100: 8.524733\n",
      "adversarial loss at step 3100: 1.0000001e-07\n",
      "discriminator loss at step 3200: 8.533635\n",
      "adversarial loss at step 3200: 1.0000001e-07\n",
      "discriminator loss at step 3300: 8.433186\n",
      "adversarial loss at step 3300: 1.0000001e-07\n",
      "discriminator loss at step 3400: 8.46431\n",
      "adversarial loss at step 3400: 1.0000001e-07\n",
      "discriminator loss at step 3500: 8.4729595\n",
      "adversarial loss at step 3500: 1.0000001e-07\n",
      "discriminator loss at step 3600: 8.42948\n",
      "adversarial loss at step 3600: 1.0000001e-07\n",
      "discriminator loss at step 3700: 8.429068\n",
      "adversarial loss at step 3700: 1.0000001e-07\n",
      "discriminator loss at step 3800: 8.44113\n",
      "adversarial loss at step 3800: 1.0000001e-07\n",
      "discriminator loss at step 3900: 8.530963\n",
      "adversarial loss at step 3900: 1.0000001e-07\n",
      "discriminator loss at step 4000: 8.52934\n",
      "adversarial loss at step 4000: 1.0000001e-07\n",
      "discriminator loss at step 4100: 8.432535\n",
      "adversarial loss at step 4100: 1.0000001e-07\n",
      "discriminator loss at step 4200: 8.447996\n",
      "adversarial loss at step 4200: 1.0000001e-07\n",
      "discriminator loss at step 4300: 8.492284\n",
      "adversarial loss at step 4300: 1.0000001e-07\n",
      "discriminator loss at step 4400: 8.440259\n",
      "adversarial loss at step 4400: 1.0000001e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start:stop]\n",
    "    combined_images = np.concatenate([generated_images,real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch(combined_images,labels)\n",
    "    \n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    \n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        #gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(\"discriminator loss at step %s: %s\" % (step,d_loss))\n",
    "        print(\"adversarial loss at step %s: %s\" % (step,a_loss))\n",
    "        \n",
    "        img2 = image.array_to_img(generated_images[0] * 255. , scale=False)\n",
    "        img2.save(os.path.join(save_dir,\"generated_frog\"+str(step)+\".png\"))\n",
    "        \n",
    "        img3 = image.array_to_img(real_images[0]*255.,scale=False)\n",
    "        img3.save(os.path.join(save_dir,\"real_flog\"+str(step)+\".png\"))\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
